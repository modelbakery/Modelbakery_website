---
title: 'The Practical Approach of Multiple Linear Regression Model'
author: Package Build
date: '2021-11-03'
slug: back-to-the-basic-what-is-regression-function
categories:
  - R
tags:
  - Academic
  - Regression
  - Model Interpretation
  - R
subtitle: 'A general class of regression models and how to interpret these models'
summary: ''
authors: []
lastmod: '2021-11-03T13:30:59+09:00'
featured: no 
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
draft: TRUE
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>
<script src="{{< blogdown/postref >}}index.en_files/kePrint/kePrint.js"></script>
<link href="{{< blogdown/postref >}}index.en_files/lightable/lightable.css" rel="stylesheet" />


<p>The concept I first learnt about multiple linear regression was too good to be true, to be applied in the real world data. This view I once had on linear regression differ greatly from one I have now. Simplicity is the best, but the work behind?- seeking deeply into the what’s called “root cause” is simply a time investment. That said, the better we are with regression, the better we will understand the hidden problems and not be betrayed by algorithms.</p>
<p>In this post, I will be focusing on variable transformation, multicollinearity, VIF, adjusted R-squared, and variable selection to come up with acceptable accuracy without relaxing the assumption of linearity.</p>
<p>Contents:</p>
<p>Study</p>
<ul>
<li>What is multiple linear regression function
<ul>
<li>Why linear regression?</li>
<li>What are its assumptions and difference with linear regression?</li>
<li>Estimation of the parameters by least squares</li>
<li>Assessing the accuracy of the Coefficient Estimates</li>
<li>Hypothesis Testing (t-test)</li>
<li>Assessing the Overall Accuracy of the Model</li>
<li>Variable Selection</li>
<li>Model Selection</li>
</ul></li>
<li>Business Case Study
<ul>
<li>Variable Interaction (Synergy Effect: Feature Engineering &amp; Business Strategy)</li>
</ul></li>
</ul>
<div id="general-notation-for" class="section level2">
<h2>General notation for</h2>
<p>Its general notation:</p>
<p>f(x) = E(Y|X =x)</p>
<p>Depending on the complexity of the function, we may be able to understand how each components Xj affects Y, and therefore the interpretable level of parameters with respect to independent X variables influencing on Y.</p>
<p>Thus models, even within Regression, have many uses and those amongst them. Some of its models would be easier to interpret than others but stronger the assumptions and its limitations to follow. I mean there is really no “free-lunch” right?</p>
<p>Before I begin explore the assumptions and algorithms of different regression models. Lets try to understand the general scheme of ideal function - explained by …</p>
<ul>
<li>Conditional average
So is there an ideal f(X)?</li>
</ul>
</div>
<div id="why-linear-regression" class="section level2">
<h2>Why linear regression?</h2>
<p>I always had this wonder. How do we know in what situation, the linear approximation is reasonable assumption to be made? - Well, most of the times never. Does that make linear regression any less vulable? Absolutley not, right?</p>
<blockquote>
<p>“If I had an hour to solve a problem and my life depended on the solution, I would spend the first 55 minutes determining the proper question to ask … for once I know the proper question, I could solve the problem in less than five minutes.”
—Albert Einstein</p>
</blockquote>
<p>I believe that the more complicated the problem is, the more important its interpretation becomes.
In other words, we should always consider the possibility of simpler way to approach any form of problems.</p>
</div>
<div id="load-libraries" class="section level2">
<h2>Load Libraries</h2>
<pre class="r"><code>library(MASS)
library(ISLR)

library(tidyverse)
library(psych)
library(skimr)
library(car)
library(janitor)
library(tidyquant)
library(lares)
library(leaps)
library(broom)

library(caret)
library(tidymodels)

library(hrbrthemes)
library(GGally)
library(viridis)
library(kableExtra)
library(gridExtra)</code></pre>
<pre class="r"><code>data(Boston)

describe(Boston) %&gt;% kbl() %&gt;% kable_minimal()</code></pre>
<table class=" lightable-minimal" style="font-family: &quot;Trebuchet MS&quot;, verdana, sans-serif; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
vars
</th>
<th style="text-align:right;">
n
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
median
</th>
<th style="text-align:right;">
trimmed
</th>
<th style="text-align:right;">
mad
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
<th style="text-align:right;">
range
</th>
<th style="text-align:right;">
skew
</th>
<th style="text-align:right;">
kurtosis
</th>
<th style="text-align:right;">
se
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
crim
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
3.6135236
</td>
<td style="text-align:right;">
8.6015451
</td>
<td style="text-align:right;">
0.25651
</td>
<td style="text-align:right;">
1.6816300
</td>
<td style="text-align:right;">
0.3283218
</td>
<td style="text-align:right;">
0.00632
</td>
<td style="text-align:right;">
88.9762
</td>
<td style="text-align:right;">
88.96988
</td>
<td style="text-align:right;">
5.1922223
</td>
<td style="text-align:right;">
36.5958159
</td>
<td style="text-align:right;">
0.3823853
</td>
</tr>
<tr>
<td style="text-align:left;">
zn
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
11.3636364
</td>
<td style="text-align:right;">
23.3224530
</td>
<td style="text-align:right;">
0.00000
</td>
<td style="text-align:right;">
5.0800493
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.00000
</td>
<td style="text-align:right;">
100.0000
</td>
<td style="text-align:right;">
100.00000
</td>
<td style="text-align:right;">
2.2124881
</td>
<td style="text-align:right;">
3.9523873
</td>
<td style="text-align:right;">
1.0368095
</td>
</tr>
<tr>
<td style="text-align:left;">
indus
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
11.1367787
</td>
<td style="text-align:right;">
6.8603529
</td>
<td style="text-align:right;">
9.69000
</td>
<td style="text-align:right;">
10.9318719
</td>
<td style="text-align:right;">
9.3700320
</td>
<td style="text-align:right;">
0.46000
</td>
<td style="text-align:right;">
27.7400
</td>
<td style="text-align:right;">
27.28000
</td>
<td style="text-align:right;">
0.2932747
</td>
<td style="text-align:right;">
-1.2401949
</td>
<td style="text-align:right;">
0.3049799
</td>
</tr>
<tr>
<td style="text-align:left;">
chas
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
0.0691700
</td>
<td style="text-align:right;">
0.2539940
</td>
<td style="text-align:right;">
0.00000
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.00000
</td>
<td style="text-align:right;">
1.0000
</td>
<td style="text-align:right;">
1.00000
</td>
<td style="text-align:right;">
3.3857377
</td>
<td style="text-align:right;">
9.4819703
</td>
<td style="text-align:right;">
0.0112914
</td>
</tr>
<tr>
<td style="text-align:left;">
nox
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
0.5546951
</td>
<td style="text-align:right;">
0.1158777
</td>
<td style="text-align:right;">
0.53800
</td>
<td style="text-align:right;">
0.5450601
</td>
<td style="text-align:right;">
0.1297275
</td>
<td style="text-align:right;">
0.38500
</td>
<td style="text-align:right;">
0.8710
</td>
<td style="text-align:right;">
0.48600
</td>
<td style="text-align:right;">
0.7249897
</td>
<td style="text-align:right;">
-0.0874106
</td>
<td style="text-align:right;">
0.0051514
</td>
</tr>
<tr>
<td style="text-align:left;">
rm
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
6.2846344
</td>
<td style="text-align:right;">
0.7026171
</td>
<td style="text-align:right;">
6.20850
</td>
<td style="text-align:right;">
6.2528744
</td>
<td style="text-align:right;">
0.5122383
</td>
<td style="text-align:right;">
3.56100
</td>
<td style="text-align:right;">
8.7800
</td>
<td style="text-align:right;">
5.21900
</td>
<td style="text-align:right;">
0.4012223
</td>
<td style="text-align:right;">
1.8418324
</td>
<td style="text-align:right;">
0.0312351
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
68.5749012
</td>
<td style="text-align:right;">
28.1488614
</td>
<td style="text-align:right;">
77.50000
</td>
<td style="text-align:right;">
71.1960591
</td>
<td style="text-align:right;">
28.9848300
</td>
<td style="text-align:right;">
2.90000
</td>
<td style="text-align:right;">
100.0000
</td>
<td style="text-align:right;">
97.10000
</td>
<td style="text-align:right;">
-0.5954162
</td>
<td style="text-align:right;">
-0.9780297
</td>
<td style="text-align:right;">
1.2513695
</td>
</tr>
<tr>
<td style="text-align:left;">
dis
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
3.7950427
</td>
<td style="text-align:right;">
2.1057101
</td>
<td style="text-align:right;">
3.20745
</td>
<td style="text-align:right;">
3.5393786
</td>
<td style="text-align:right;">
1.9142590
</td>
<td style="text-align:right;">
1.12960
</td>
<td style="text-align:right;">
12.1265
</td>
<td style="text-align:right;">
10.99690
</td>
<td style="text-align:right;">
1.0057898
</td>
<td style="text-align:right;">
0.4575916
</td>
<td style="text-align:right;">
0.0936102
</td>
</tr>
<tr>
<td style="text-align:left;">
rad
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
9.5494071
</td>
<td style="text-align:right;">
8.7072594
</td>
<td style="text-align:right;">
5.00000
</td>
<td style="text-align:right;">
8.7339901
</td>
<td style="text-align:right;">
2.9652000
</td>
<td style="text-align:right;">
1.00000
</td>
<td style="text-align:right;">
24.0000
</td>
<td style="text-align:right;">
23.00000
</td>
<td style="text-align:right;">
0.9988651
</td>
<td style="text-align:right;">
-0.8789291
</td>
<td style="text-align:right;">
0.3870849
</td>
</tr>
<tr>
<td style="text-align:left;">
tax
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
408.2371542
</td>
<td style="text-align:right;">
168.5371161
</td>
<td style="text-align:right;">
330.00000
</td>
<td style="text-align:right;">
400.0443350
</td>
<td style="text-align:right;">
108.2298000
</td>
<td style="text-align:right;">
187.00000
</td>
<td style="text-align:right;">
711.0000
</td>
<td style="text-align:right;">
524.00000
</td>
<td style="text-align:right;">
0.6659891
</td>
<td style="text-align:right;">
-1.1503176
</td>
<td style="text-align:right;">
7.4923887
</td>
</tr>
<tr>
<td style="text-align:left;">
ptratio
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
18.4555336
</td>
<td style="text-align:right;">
2.1649455
</td>
<td style="text-align:right;">
19.05000
</td>
<td style="text-align:right;">
18.6625616
</td>
<td style="text-align:right;">
1.7049900
</td>
<td style="text-align:right;">
12.60000
</td>
<td style="text-align:right;">
22.0000
</td>
<td style="text-align:right;">
9.40000
</td>
<td style="text-align:right;">
-0.7975743
</td>
<td style="text-align:right;">
-0.3048010
</td>
<td style="text-align:right;">
0.0962436
</td>
</tr>
<tr>
<td style="text-align:left;">
black
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
356.6740316
</td>
<td style="text-align:right;">
91.2948644
</td>
<td style="text-align:right;">
391.44000
</td>
<td style="text-align:right;">
383.1695074
</td>
<td style="text-align:right;">
8.0949960
</td>
<td style="text-align:right;">
0.32000
</td>
<td style="text-align:right;">
396.9000
</td>
<td style="text-align:right;">
396.58000
</td>
<td style="text-align:right;">
-2.8732597
</td>
<td style="text-align:right;">
7.1037150
</td>
<td style="text-align:right;">
4.0585518
</td>
</tr>
<tr>
<td style="text-align:left;">
lstat
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
12.6530632
</td>
<td style="text-align:right;">
7.1410615
</td>
<td style="text-align:right;">
11.36000
</td>
<td style="text-align:right;">
11.8990394
</td>
<td style="text-align:right;">
7.1090670
</td>
<td style="text-align:right;">
1.73000
</td>
<td style="text-align:right;">
37.9700
</td>
<td style="text-align:right;">
36.24000
</td>
<td style="text-align:right;">
0.9010929
</td>
<td style="text-align:right;">
0.4628171
</td>
<td style="text-align:right;">
0.3174589
</td>
</tr>
<tr>
<td style="text-align:left;">
medv
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
506
</td>
<td style="text-align:right;">
22.5328063
</td>
<td style="text-align:right;">
9.1971041
</td>
<td style="text-align:right;">
21.20000
</td>
<td style="text-align:right;">
21.5623153
</td>
<td style="text-align:right;">
5.9304000
</td>
<td style="text-align:right;">
5.00000
</td>
<td style="text-align:right;">
50.0000
</td>
<td style="text-align:right;">
45.00000
</td>
<td style="text-align:right;">
1.1015373
</td>
<td style="text-align:right;">
1.4509837
</td>
<td style="text-align:right;">
0.4088611
</td>
</tr>
</tbody>
</table>
</div>
<div id="understanding-data-boston-housing-data" class="section level2">
<h2>Understanding Data: Boston Housing Data</h2>
<div id="aim-of-the-analysis" class="section level4">
<h4>Aim of the Analysis</h4>
<p>The Boston Housing data set was analysed by Harrison and Rubinfeld, who wanted to find out whether “clean air” had an influence on house prices.</p>
</div>
<div id="segmenting-variables-macro-to-micro" class="section level4">
<h4>Segmenting Variables: Macro to Micro</h4>
<p>[1] Macro{External Influence}</p>
<p><strong>chas</strong>: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).</p>
<p><strong>age</strong>: proportion of owner-occupied units built prior to 1940.</p>
<p>[2] Industry/land/district</p>
<p><strong>zn</strong>: proportion of residential land zoned for lots over 25,000 sq.ft.</p>
<p><strong>indus</strong>: proportion of non-retail business acres per town.</p>
<p><strong>dis</strong>: weighted mean of distances to five Boston employment centres.</p>
<p><strong>rad</strong>: index of accessibility to radial highways.</p>
<p>[3] Population</p>
<p><strong>lstat</strong>: lower status of the population (percent).</p>
<p><strong>black</strong>: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.</p>
<p><strong>ptratio</strong>: pupil-teacher ratio by town.</p>
<p>[3] Cause/result</p>
<p><strong>nox</strong>: nitrogen oxides concentration (parts per 10 million)</p>
<p><strong>tax</strong>: full-value property-tax rate per $10,000.</p>
<p><strong>crim</strong>: per capita crime rate by town.</p>
<p>[4] Direct influence</p>
<p><strong>rm</strong>: average number of rooms per dwelling.</p>
<p>[5] Target variable</p>
<p><strong>medv</strong>: median value of owner-occupied homes in $1000s.</p>
</div>
</div>
<div id="distribution-of-target-variable" class="section level2">
<h2>Distribution of Target Variable</h2>
<pre class="r"><code># Data preparation: logarithm target medv 
lBoston &lt;- Boston %&gt;% 
  mutate(log_medv = log(medv))
  
# Distribution of target medv 
P_medv &lt;- ggplot(Boston, aes(x = medv)) +
  geom_density(aes(x = medv, y = ..density..)) +
    geom_density(color=&quot;black&quot;, lwd =1.5, fill = palette_light()[1])  +
    stat_function(fun=dnorm, 
                args = list(mean=mean(Boston$medv),
                            sd=sd(Boston$medv)),
                color=&quot;red&quot;, lwd = 1) +
  theme_minimal()

# Distribution of logarithm target medv 
P_lmedv &lt;- lBoston %&gt;% 
  ggplot(aes(x = log_medv)) +
  geom_density(aes(x = log_medv, y = ..density..)) +
    geom_density(color=&quot;black&quot;, lwd =1.5, fill = palette_light()[1])  +
    stat_function(fun=dnorm, 
                args = list(mean=mean(lBoston$log_medv),
                            sd=sd(lBoston$log_medv)),
                color=&quot;red&quot;, lwd = 1) +
  theme_minimal()

# Shapiro-Wilk normality test: Both rejects the Null Hypothesis stating that the target data does not fit the normal distribution with 95% confidence. Significant departure from normality was found. 
shapiro.test(Boston$medv)$p.value</code></pre>
<pre><code>## [1] 4.941386e-16</code></pre>
<pre class="r"><code>shapiro.test(lBoston$log_medv)$p.value</code></pre>
<pre><code>## [1] 1.935427e-07</code></pre>
<pre class="r"><code>par(mfrow = c(1,2))
qqnorm(Boston$medv); qqline(Boston$medv, col =2)
qqnorm(lBoston$log_medv); qqline(lBoston$log_medv, col =2)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>grid.arrange(P_medv, P_lmedv)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-3-2.png" width="672" />
By looking at the p-values, the log transform departure less significant from normality hence I will carry logarithm medv. The R squared estimatation will be computed after inversion using exponent function. <Must Remember></p>
</div>
<div id="visualisation-boxplot-histogram" class="section level2">
<h2>Visualisation: Boxplot &amp; Histogram</h2>
<ul>
<li><p>Scaling or transformation should be considered</p></li>
<li><p>Outlier treatment should be considered</p></li>
</ul>
<pre class="r"><code># Quick boxplot:
boxplot(Boston)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code># Customised facet histogram: can be found on my GitHub :)  
generator_hist_facet(lBoston)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
</div>
<div id="ggally-visualisation" class="section level2">
<h2>GGally Visualisation</h2>
<pre class="r"><code># Data preparation for GGally visualisation with observation split at meidan Y value. 
Boston_medv_median &lt;- Boston %&gt;% 
  mutate(median_medv_cutoff = ifelse(medv &gt; median(medv), 1, 0),
         median_medv_cutoff = as.factor(median_medv_cutoff)) 

# GGally ggpairs plot for variables upto age 
GGally::ggpairs(Boston_medv_median[ ,c(14,1:7, 15)],
                aes(color=median_medv_cutoff, alpha = 0.75),
                lower = list(continous = &quot;smooth&quot;)) +
  theme_bw() +
  labs(title = &quot;prostate cancer&quot;) +
  theme(plot.title = element_text(face = &#39;bold&#39;,
                                  colour = &#39;black&#39;,
                                  hjust = 0.5, size = 12))</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code># GGally ggpairs plot for variables from dis ~ lstat 
GGally::ggpairs(Boston_medv_median[ ,c(14,8:15)],
                aes(color=median_medv_cutoff, alpha = 0.75),
                lower = list(continous = &quot;smooth&quot;)) +
  theme_bw() +
  labs(title = &quot;prostate cancer&quot;) +
  theme(plot.title = element_text(face = &#39;bold&#39;,
                                  colour = &#39;black&#39;,
                                  hjust = 0.5, size = 12))</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<pre class="r"><code># Gally parallel coordinates plot {PCP}
Boston_medv_median %&gt;%
  arrange(desc(median_medv_cutoff)) %&gt;%
  ggparcoord(
    columns = 1:14, groupColumn = 15,
    scale=&quot;uniminmax&quot;,
    showPoints = FALSE,
    alphaLines = 1
    ) + 
  scale_color_viridis(discrete=TRUE)+
    labs(
    title = &quot;Parallel Coordinates Plot for Boston House Price: Minmax Standardised&quot;,
    subtitle = &quot;Strong negative connection observed between lstat &amp; medv&quot;,
    caption = &quot;medv &gt; median(medv): Yellow
               medv ≤ meidan(medv): Purple&quot;,
    y = &quot;Minmax scaled medv&quot;,
    x = &quot;&quot;) +
  theme_ipsum()+
  theme(
    legend.position=&quot;default&quot;,
    plot.title = element_text(size=15)
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-6-3.png" width="672" /></p>
<p>In order to highlight the relation of medv (target Y) to the remaining 13 variables, I have split the observations with medv &gt; median(medv) as <strong>yellow</strong> lines and rest as the <strong>purple</strong> line. Some of the variables seem to be strongly related. The most obvious relation is the negative dependence between lstat and medv.For better graphical representations, the variables have been minmax scaled over the interval [0,1]. There are variables where the observations are highly concnetrated at the low region, close to zero. By means, it makes sense to consider transformation of the original data.</p>
<ul>
<li>crim -&gt; lcrim (logarithm)
<ul>
<li>Taking the logarithm makes the variable’s distribution more symmetric. Its median and the mean have moved closer to each other then they were for the original crim.</li>
</ul></li>
<li>zn -&gt; zn (binning)
<ul>
<li>There is a large number of zero values.</li>
<li>There is a noticable non-linear negative relationship with crim, noticed on PCP. Almost all the observations for which zn = 0, have a high percapita crime rate, and vice versa.</li>
<li>On the concern of house price prediction, the correlation says that there seems to be no clear linear relationship with medv. However, the residential land over its common size would obviously lead to higher property price.</li>
</ul></li>
<li>indus -&gt; lindus (logarithm)
<ul>
<li>Negative correlation with target medv observed. The relationship between the logarithms of both variables seems to be almost linear. The negative relation might result from the noise non-retail business sometimes generates and other pollution aspects.</li>
<li>Strong linear correlation with nox. Greater the proportion of non-retail business, more likely to cause a pollution hence the high nox concentration.</li>
</ul></li>
<li>chas
<ul>
<li>There are some doubt that Charles River influences the house price. That said, the districts close to the Charles River would likely to influence other factors such as the pupil/teacher ratio or the proportion of non-retail business acres. Hence, their relation may be pure coincidence or some form of hierchical interaction.</li>
</ul></li>
<li>rm -&gt; lrm (logarithm)
<ul>
<li>The number of rooms per dwelling is a direct measure of the size of the houses. Thus, I suspect rm to be strongly correlated with the target medv.<br />
</li>
<li>Outlier treatment needed.</li>
</ul></li>
<li>age -&gt; age^2.5/10000
<ul>
<li>There is no clear sign of rlationship with the house price. On top of that, usually the time, date, age factor has connection with multiple variables, which likely to inflate the VIF factor and rise multicollinearity issue.</li>
<li>Left skewed</li>
</ul></li>
<li>dis -&gt; ldis (logarithm)
<ul>
<li>The scatter plot showed hardly any linear relationship with the target, house price. However, there is a noticable non-linear relation and its logarithm does seem to preserve distance influence on the house price.</li>
</ul></li>
<li>rad -&gt; lrad (logarithm)
<ul>
<li>The one obvious thing one can observe is the subgroups of districts containing rad value, which are lose to the respective group’s mean. The boxplot from ggpair reveals that the mean value of these subgroups stays relatively the same for both low and high price of the house.</li>
<li>Its correlation with tax exceeds 0.9</li>
</ul></li>
<li>tax -&gt; ltax (logarithm)
<ul>
<li>Likewise to rad, there is a noticable subgroups on the distribution of tax value. The scatter plot shows downward curve with increase in the tax rate. There are presence of outliers in lower value subgroup but the mean difference within these groups seems to be significant to retain its information.</li>
</ul></li>
<li>ptratio -&gt; exp(0.4*ptratio)/1000
<ul>
<li>The ggpair boxplot indicates negative relation with medv.</li>
<li>The mean values of its subgroups depart significantly by high and low regime of medv.</li>
<li>The kurtosis of of its red distribution {medv &lt; median(medv)} is highly noticeable hence likely be potential predictor variable on medv.</li>
</ul></li>
<li>black -&gt; black/100
<ul>
<li><a href="https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8" class="uri">https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8</a></li>
</ul></li>
<li>lstat -&gt; lstat^0.5
<ul>
<li>Of all the variables, lstat exhibits the strongest negative relation with medv (PCP &amp; ggpairs).</li>
<li>Taking the square root removes all the outliers and gains better relation with log(mdv)</li>
</ul></li>
</ul>
</div>
<div id="feature-transformation-asymmetry-reduction" class="section level2">
<h2>Feature Transformation &amp; Asymmetry reduction</h2>
<pre class="r"><code># feature transformation/scaling 
Boston_transform &lt;- Boston %&gt;% 
  summarise(lcrim    = log(crim + 1),
            zn       = zn/10,
            lindus   = log(indus),
            chas     = chas,
            lnox     = log(nox),
            lrm      = log(rm),
            sqage    = (age^2.5)/10000,
            ldis     = log(dis),
            lrad     = log(rad),
            ltax     = log(tax),
            eptratio = exp(0.4*ptratio)/1000,
            black    = black/100,
            srlstat  = lstat^0.5,
            lmedv    = log(medv))

# Boxplots for all of the transformed variables + scaling 
Boston_transform %&gt;% 
  summarise_all(funs(x = scale(., center = TRUE, scale = TRUE))) %&gt;% 
  setNames(c(&quot;crim&quot;, &quot;zn&quot;, &quot;indus&quot;, &quot;chas&quot;, &quot;nox&quot;, &quot;rm&quot;, &quot;age&quot;, &quot;dis&quot;, &quot;rad&quot;, &quot;tax&quot;, &quot;ptratio&quot;, &quot;black&quot;, &quot;lstat&quot;, &quot;medv&quot;)) %&gt;% 
  gather(key = key, value = value, factor_key = TRUE) %&gt;% 
  ggplot(aes(key, value)) +
  geom_boxplot(fill = viridisLite::viridis(n = 20)[1], colour = &quot;yellow&quot;) +
  labs(
    title = &quot;Transformed Boston Housing Data&quot;,
    x = &quot;&quot;,
    y = &quot;Scaled Index&quot;
  ) +
  theme_dark() </code></pre>
<pre><code>## Warning: `funs()` was deprecated in dplyr 0.8.0.
## Please use a list of either functions or lambdas: 
## 
##   # Simple named list: 
##   list(mean = mean, median = median)
## 
##   # Auto named with `tibble::lst()`: 
##   tibble::lst(mean, median)
## 
##   # Using lambdas
##   list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))</code></pre>
<pre><code>## Warning: attributes are not identical across measure variables;
## they will be dropped</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Since most of the variables exhibit an asymmetry with a higher density on the left-hand side (right skewed), the logarithm transformations are proposed on most of the variables. Taking the logarithm helps to reduce the asymmetry, pushing lower values to move further away from each other whereas the distance between greater values is reduced.</p>
<p>In comparison to original data, these transformed variables are more asymmetric and where logarithm was applied, the less outliers were shown. The question is: is the upper and/or extreme always an outlier? I believe there is no straight answer hence I will carry out this transformed data set and outlier treated data set as I go along the analysis.</p>
<div id="correlation-lares-package" class="section level4">
<h4>Correlation: lares package</h4>
<pre class="r"><code># Target variable correlation plot
corr_info &lt;- corr_var(Boston_transform, 
  lmedv 
); corr_info</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code># X&#39;s cross correlation plot: display only significant correlations (at 5% level)
corr_cross_info &lt;- corr_cross(Boston_transform %&gt;% dplyr::select(-lmedv), 
  max_pvalue = 0.05,
  rm.na = FALSE
); corr_cross_info</code></pre>
<pre><code>## Returning only the top 25. You may override with the &#39;top&#39; argument</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-8-2.png" width="672" /></p>
<pre class="r"><code># Capturing data into table 
corr_tbl &lt;- corr_info$data %&gt;% dplyr::select(variables, corr)
corr_cross_tbl &lt;-corr_cross_info$data %&gt;% dplyr::select(key, label, corr)</code></pre>
</div>
<div id="linear-model-original-vs-transformed-data-set" class="section level4">
<h4>Linear Model: Original VS Transformed Data Set</h4>
<pre class="r"><code># linear model on all variables 
lm_fit_00edit &lt;- lm(medv~., data = Boston); summary(lm_fit_00edit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ ., data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.595  -2.730  -0.518   1.777  26.199 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***
## crim        -1.080e-01  3.286e-02  -3.287 0.001087 ** 
## zn           4.642e-02  1.373e-02   3.382 0.000778 ***
## indus        2.056e-02  6.150e-02   0.334 0.738288    
## chas         2.687e+00  8.616e-01   3.118 0.001925 ** 
## nox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***
## rm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***
## age          6.922e-04  1.321e-02   0.052 0.958229    
## dis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***
## rad          3.060e-01  6.635e-02   4.613 5.07e-06 ***
## tax         -1.233e-02  3.760e-03  -3.280 0.001112 ** 
## ptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***
## black        9.312e-03  2.686e-03   3.467 0.000573 ***
## lstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.745 on 492 degrees of freedom
## Multiple R-squared:  0.7406, Adjusted R-squared:  0.7338 
## F-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># linear model on all transformed variables 
lm_fit_01edit &lt;- lm(lmedv~., data = Boston_transform); summary(lm_fit_01edit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = lmedv ~ ., data = Boston_transform)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.76220 -0.11102 -0.00600  0.09499  0.77740 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.964669   0.362512  10.937  &lt; 2e-16 ***
## lcrim       -0.135032   0.020403  -6.618 9.53e-11 ***
## zn           0.007416   0.005453   1.360 0.174453    
## lindus      -0.027081   0.021415  -1.265 0.206614    
## chas         0.102059   0.035181   2.901 0.003886 ** 
## lnox        -0.263992   0.098659  -2.676 0.007704 ** 
## lrm          0.398020   0.105803   3.762 0.000189 ***
## sqage        0.006585   0.004605   1.430 0.153363    
## ldis        -0.234407   0.036182  -6.479 2.25e-10 ***
## lrad         0.124417   0.020891   5.956 4.94e-09 ***
## ltax        -0.139092   0.047304  -2.940 0.003433 ** 
## eptratio    -0.037756   0.007767  -4.861 1.57e-06 ***
## black        0.029055   0.011127   2.611 0.009296 ** 
## srlstat     -0.249327   0.015567 -16.016  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1927 on 492 degrees of freedom
## Multiple R-squared:  0.7835, Adjusted R-squared:  0.7778 
## F-statistic:   137 on 13 and 492 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>glance(lm_fit_00edit) %&gt;% kbl %&gt;% kable_material()</code></pre>
<table class=" lightable-material" style="font-family: &quot;Source Sans Pro&quot;, helvetica, sans-serif; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
r.squared
</th>
<th style="text-align:right;">
adj.r.squared
</th>
<th style="text-align:right;">
sigma
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
logLik
</th>
<th style="text-align:right;">
AIC
</th>
<th style="text-align:right;">
BIC
</th>
<th style="text-align:right;">
deviance
</th>
<th style="text-align:right;">
df.residual
</th>
<th style="text-align:right;">
nobs
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.7406427
</td>
<td style="text-align:right;">
0.7337897
</td>
<td style="text-align:right;">
4.745298
</td>
<td style="text-align:right;">
108.0767
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
-1498.804
</td>
<td style="text-align:right;">
3027.609
</td>
<td style="text-align:right;">
3091.007
</td>
<td style="text-align:right;">
11078.78
</td>
<td style="text-align:right;">
492
</td>
<td style="text-align:right;">
506
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>glance(lm_fit_01edit) %&gt;% kbl %&gt;% kable_material()</code></pre>
<table class=" lightable-material" style="font-family: &quot;Source Sans Pro&quot;, helvetica, sans-serif; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
r.squared
</th>
<th style="text-align:right;">
adj.r.squared
</th>
<th style="text-align:right;">
sigma
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
logLik
</th>
<th style="text-align:right;">
AIC
</th>
<th style="text-align:right;">
BIC
</th>
<th style="text-align:right;">
deviance
</th>
<th style="text-align:right;">
df.residual
</th>
<th style="text-align:right;">
nobs
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.7835214
</td>
<td style="text-align:right;">
0.7778015
</td>
<td style="text-align:right;">
0.1926796
</td>
<td style="text-align:right;">
136.9802
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
122.3595
</td>
<td style="text-align:right;">
-214.7191
</td>
<td style="text-align:right;">
-151.321
</td>
<td style="text-align:right;">
18.2657
</td>
<td style="text-align:right;">
492
</td>
<td style="text-align:right;">
506
</td>
</tr>
</tbody>
</table>
<p>From the summary statistics computed with glance function, it is clear that asymmetric reduced data having positive influence on the overall accuracy of the linear model and OLS approach.</p>
<ul>
<li><p>Higher R-squared &amp; adj.R-squared, and lower AIC &amp; BIC</p></li>
<li><p>Less number of statistically significant variables depicted (t_value &gt; 2) on the model. Optimal parameters</p></li>
</ul>
</div>
</div>
<div id="data-partitioning-traintest-73" class="section level2">
<h2>Data Partitioning: train:test (7:3)</h2>
<pre class="r"><code>set.seed(42)
tidy_split &lt;- initial_split(Boston_transform, prop = .7,
                            strata = lmedv)
Boston_tr &lt;- training(tidy_split)
Boston_te &lt;- testing(tidy_split)</code></pre>
</div>
<div id="summary-table-for-variable-coefficient-correlation" class="section level2">
<h2>Summary table for variable coefficient &amp; correlation</h2>
<pre class="r"><code>var_names &lt;- colnames(Boston_transform %&gt;% dplyr::select(lmedv, everything()))

summary_relationship_tbl &lt;- summary(lm_fit_00edit)$coefficients[,c(1,3:4)] %&gt;% 
  as_tibble() %&gt;% 
  cbind(var_names) %&gt;% 
  dplyr::select(var_names, everything()) %&gt;% 
  left_join(corr_tbl, by = c(&quot;var_names&quot; = &quot;variables&quot;)) %&gt;% 
  left_join(corr_cross_tbl, by = c(&quot;var_names&quot; = &quot;key&quot;)) %&gt;% 
  setNames(c(&quot;var_names&quot;, &quot;Estimate&quot;, &quot;t_stats&quot;, &quot;p_value&quot;, &quot;corr&quot;, &quot;label&quot;, &quot;cross_corr&quot;)) %&gt;% 
  arrange(cross_corr)

summary_relationship_tbl %&gt;% kbl() %&gt;% kable_material()</code></pre>
<table class=" lightable-material" style="font-family: &quot;Source Sans Pro&quot;, helvetica, sans-serif; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
var_names
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
t_stats
</th>
<th style="text-align:right;">
p_value
</th>
<th style="text-align:right;">
corr
</th>
<th style="text-align:left;">
label
</th>
<th style="text-align:right;">
cross_corr
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
lnox
</td>
<td style="text-align:right;">
-17.7666112
</td>
<td style="text-align:right;">
-4.6512574
</td>
<td style="text-align:right;">
0.0000042
</td>
<td style="text-align:right;">
-0.515251
</td>
<td style="text-align:left;">
lnox + ldis
</td>
<td style="text-align:right;">
-0.860018
</td>
</tr>
<tr>
<td style="text-align:left;">
sqage
</td>
<td style="text-align:right;">
0.0006922
</td>
<td style="text-align:right;">
0.0524024
</td>
<td style="text-align:right;">
0.9582293
</td>
<td style="text-align:right;">
-0.482096
</td>
<td style="text-align:left;">
sqage + ldis
</td>
<td style="text-align:right;">
-0.795991
</td>
</tr>
<tr>
<td style="text-align:left;">
lindus
</td>
<td style="text-align:right;">
0.0205586
</td>
<td style="text-align:right;">
0.3343100
</td>
<td style="text-align:right;">
0.7382881
</td>
<td style="text-align:right;">
-0.553887
</td>
<td style="text-align:left;">
lindus + ldis
</td>
<td style="text-align:right;">
-0.730297
</td>
</tr>
<tr>
<td style="text-align:left;">
lcrim
</td>
<td style="text-align:right;">
-0.1080114
</td>
<td style="text-align:right;">
-3.2865169
</td>
<td style="text-align:right;">
0.0010868
</td>
<td style="text-align:right;">
-0.599781
</td>
<td style="text-align:left;">
lcrim + ldis
</td>
<td style="text-align:right;">
-0.676479
</td>
</tr>
<tr>
<td style="text-align:left;">
zn
</td>
<td style="text-align:right;">
0.0464205
</td>
<td style="text-align:right;">
3.3815763
</td>
<td style="text-align:right;">
0.0007781
</td>
<td style="text-align:right;">
0.363344
</td>
<td style="text-align:left;">
zn + lindus
</td>
<td style="text-align:right;">
-0.655898
</td>
</tr>
<tr>
<td style="text-align:left;">
lrm
</td>
<td style="text-align:right;">
3.8098652
</td>
<td style="text-align:right;">
9.1161402
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.610437
</td>
<td style="text-align:left;">
lrm + srlstat
</td>
<td style="text-align:right;">
-0.639439
</td>
</tr>
<tr>
<td style="text-align:left;">
ldis
</td>
<td style="text-align:right;">
-1.4755668
</td>
<td style="text-align:right;">
-7.3980036
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.405721
</td>
<td style="text-align:left;">
ldis + ltax
</td>
<td style="text-align:right;">
-0.599621
</td>
</tr>
<tr>
<td style="text-align:left;">
lindus
</td>
<td style="text-align:right;">
0.0205586
</td>
<td style="text-align:right;">
0.3343100
</td>
<td style="text-align:right;">
0.7382881
</td>
<td style="text-align:right;">
-0.553887
</td>
<td style="text-align:left;">
lindus + lrad
</td>
<td style="text-align:right;">
0.580533
</td>
</tr>
<tr>
<td style="text-align:left;">
zn
</td>
<td style="text-align:right;">
0.0464205
</td>
<td style="text-align:right;">
3.3815763
</td>
<td style="text-align:right;">
0.0007781
</td>
<td style="text-align:right;">
0.363344
</td>
<td style="text-align:left;">
zn + ldis
</td>
<td style="text-align:right;">
0.590655
</td>
</tr>
<tr>
<td style="text-align:left;">
lcrim
</td>
<td style="text-align:right;">
-0.1080114
</td>
<td style="text-align:right;">
-3.2865169
</td>
<td style="text-align:right;">
0.0010868
</td>
<td style="text-align:right;">
-0.599781
</td>
<td style="text-align:left;">
lcrim + srlstat
</td>
<td style="text-align:right;">
0.591480
</td>
</tr>
<tr>
<td style="text-align:left;">
lcrim
</td>
<td style="text-align:right;">
-0.1080114
</td>
<td style="text-align:right;">
-3.2865169
</td>
<td style="text-align:right;">
0.0010868
</td>
<td style="text-align:right;">
-0.599781
</td>
<td style="text-align:left;">
lcrim + sqage
</td>
<td style="text-align:right;">
0.604537
</td>
</tr>
<tr>
<td style="text-align:left;">
lnox
</td>
<td style="text-align:right;">
-17.7666112
</td>
<td style="text-align:right;">
-4.6512574
</td>
<td style="text-align:right;">
0.0000042
</td>
<td style="text-align:right;">
-0.515251
</td>
<td style="text-align:left;">
lnox + srlstat
</td>
<td style="text-align:right;">
0.609437
</td>
</tr>
<tr>
<td style="text-align:left;">
lnox
</td>
<td style="text-align:right;">
-17.7666112
</td>
<td style="text-align:right;">
-4.6512574
</td>
<td style="text-align:right;">
0.0000042
</td>
<td style="text-align:right;">
-0.515251
</td>
<td style="text-align:left;">
lnox + lrad
</td>
<td style="text-align:right;">
0.612948
</td>
</tr>
<tr>
<td style="text-align:left;">
lindus
</td>
<td style="text-align:right;">
0.0205586
</td>
<td style="text-align:right;">
0.3343100
</td>
<td style="text-align:right;">
0.7382881
</td>
<td style="text-align:right;">
-0.553887
</td>
<td style="text-align:left;">
lindus + srlstat
</td>
<td style="text-align:right;">
0.621379
</td>
</tr>
<tr>
<td style="text-align:left;">
lcrim
</td>
<td style="text-align:right;">
-0.1080114
</td>
<td style="text-align:right;">
-3.2865169
</td>
<td style="text-align:right;">
0.0010868
</td>
<td style="text-align:right;">
-0.599781
</td>
<td style="text-align:left;">
lcrim + lindus
</td>
<td style="text-align:right;">
0.626457
</td>
</tr>
<tr>
<td style="text-align:left;">
sqage
</td>
<td style="text-align:right;">
0.0006922
</td>
<td style="text-align:right;">
0.0524024
</td>
<td style="text-align:right;">
0.9582293
</td>
<td style="text-align:right;">
-0.482096
</td>
<td style="text-align:left;">
sqage + srlstat
</td>
<td style="text-align:right;">
0.637140
</td>
</tr>
<tr>
<td style="text-align:left;">
lindus
</td>
<td style="text-align:right;">
0.0205586
</td>
<td style="text-align:right;">
0.3343100
</td>
<td style="text-align:right;">
0.7382881
</td>
<td style="text-align:right;">
-0.553887
</td>
<td style="text-align:left;">
lindus + sqage
</td>
<td style="text-align:right;">
0.658137
</td>
</tr>
<tr>
<td style="text-align:left;">
lindus
</td>
<td style="text-align:right;">
0.0205586
</td>
<td style="text-align:right;">
0.3343100
</td>
<td style="text-align:right;">
0.7382881
</td>
<td style="text-align:right;">
-0.553887
</td>
<td style="text-align:left;">
lindus + ltax
</td>
<td style="text-align:right;">
0.659285
</td>
</tr>
<tr>
<td style="text-align:left;">
lnox
</td>
<td style="text-align:right;">
-17.7666112
</td>
<td style="text-align:right;">
-4.6512574
</td>
<td style="text-align:right;">
0.0000042
</td>
<td style="text-align:right;">
-0.515251
</td>
<td style="text-align:left;">
lnox + ltax
</td>
<td style="text-align:right;">
0.668307
</td>
</tr>
<tr>
<td style="text-align:left;">
lcrim
</td>
<td style="text-align:right;">
-0.1080114
</td>
<td style="text-align:right;">
-3.2865169
</td>
<td style="text-align:right;">
0.0010868
</td>
<td style="text-align:right;">
-0.599781
</td>
<td style="text-align:left;">
lcrim + lnox
</td>
<td style="text-align:right;">
0.716788
</td>
</tr>
<tr>
<td style="text-align:left;">
lindus
</td>
<td style="text-align:right;">
0.0205586
</td>
<td style="text-align:right;">
0.3343100
</td>
<td style="text-align:right;">
0.7382881
</td>
<td style="text-align:right;">
-0.553887
</td>
<td style="text-align:left;">
lindus + lnox
</td>
<td style="text-align:right;">
0.750463
</td>
</tr>
<tr>
<td style="text-align:left;">
lnox
</td>
<td style="text-align:right;">
-17.7666112
</td>
<td style="text-align:right;">
-4.6512574
</td>
<td style="text-align:right;">
0.0000042
</td>
<td style="text-align:right;">
-0.515251
</td>
<td style="text-align:left;">
lnox + sqage
</td>
<td style="text-align:right;">
0.783129
</td>
</tr>
<tr>
<td style="text-align:left;">
lrad
</td>
<td style="text-align:right;">
0.3060495
</td>
<td style="text-align:right;">
4.6128998
</td>
<td style="text-align:right;">
0.0000051
</td>
<td style="text-align:right;">
-0.434513
</td>
<td style="text-align:left;">
lrad + ltax
</td>
<td style="text-align:right;">
0.820487
</td>
</tr>
<tr>
<td style="text-align:left;">
lcrim
</td>
<td style="text-align:right;">
-0.1080114
</td>
<td style="text-align:right;">
-3.2865169
</td>
<td style="text-align:right;">
0.0010868
</td>
<td style="text-align:right;">
-0.599781
</td>
<td style="text-align:left;">
lcrim + ltax
</td>
<td style="text-align:right;">
0.824690
</td>
</tr>
<tr>
<td style="text-align:left;">
lcrim
</td>
<td style="text-align:right;">
-0.1080114
</td>
<td style="text-align:right;">
-3.2865169
</td>
<td style="text-align:right;">
0.0010868
</td>
<td style="text-align:right;">
-0.599781
</td>
<td style="text-align:left;">
lcrim + lrad
</td>
<td style="text-align:right;">
0.838352
</td>
</tr>
<tr>
<td style="text-align:left;">
lmedv
</td>
<td style="text-align:right;">
36.4594884
</td>
<td style="text-align:right;">
7.1440742
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
chas
</td>
<td style="text-align:right;">
2.6867338
</td>
<td style="text-align:right;">
3.1183809
</td>
<td style="text-align:right;">
0.0019250
</td>
<td style="text-align:right;">
0.158412
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
ltax
</td>
<td style="text-align:right;">
-0.0123346
</td>
<td style="text-align:right;">
-3.2800091
</td>
<td style="text-align:right;">
0.0011116
</td>
<td style="text-align:right;">
-0.557184
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
eptratio
</td>
<td style="text-align:right;">
-0.9527472
</td>
<td style="text-align:right;">
-7.2825106
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
-0.508224
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
black
</td>
<td style="text-align:right;">
0.0093117
</td>
<td style="text-align:right;">
3.4667926
</td>
<td style="text-align:right;">
0.0005729
</td>
<td style="text-align:right;">
0.402382
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
srlstat
</td>
<td style="text-align:right;">
-0.5247584
</td>
<td style="text-align:right;">
-10.3471458
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
-0.825024
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
</div>
<div id="variable-selection-best-subsets-selection" class="section level2">
<h2>Variable Selection: Best Subsets Selection</h2>
<pre class="r"><code>lmfit_00tr &lt;- lm(lmedv~., Boston_tr); summary(lmfit_00tr)</code></pre>
<pre><code>## 
## Call:
## lm(formula = lmedv ~ ., data = Boston_tr)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.76352 -0.10686 -0.00819  0.08682  0.79123 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.687774   0.465807   7.917 3.53e-14 ***
## lcrim       -0.145978   0.024003  -6.082 3.22e-09 ***
## zn           0.006761   0.006579   1.028  0.30487    
## lindus      -0.027556   0.025225  -1.092  0.27543    
## chas         0.104987   0.038958   2.695  0.00739 ** 
## lnox        -0.274483   0.117073  -2.345  0.01963 *  
## lrm          0.527551   0.141663   3.724  0.00023 ***
## sqage        0.005481   0.005473   1.001  0.31736    
## ldis        -0.242247   0.043863  -5.523 6.66e-08 ***
## lrad         0.138331   0.025670   5.389 1.33e-07 ***
## ltax        -0.151940   0.058873  -2.581  0.01028 *  
## eptratio    -0.038161   0.009271  -4.116 4.85e-05 ***
## black        0.037392   0.013020   2.872  0.00434 ** 
## srlstat     -0.224428   0.019777 -11.348  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1921 on 338 degrees of freedom
## Multiple R-squared:  0.7882, Adjusted R-squared:  0.7801 
## F-statistic: 96.78 on 13 and 338 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>regsubfit_full &lt;- regsubsets(lmedv~.,
                        data= Boston_tr, 
                        intercept = T,
                        method = c(&quot;backward&quot;, &quot;forward&quot;, &quot;seqrep&quot;),
                        nvmax = 13)

regfit_summary &lt;- summary(regsubfit_full)</code></pre>
<blockquote>
<pre><code>      Df Sum of Sq    RSS     AIC</code></pre>
<p><none> 12.544 -1149.7
- lindus 1 0.0943 12.638 -1149.1
- lnox 1 0.1804 12.724 -1146.7
- ltax 1 0.2100 12.754 -1145.9
- chas 1 0.2974 12.841 -1143.5
- black 1 0.3248 12.869 -1142.7
- lrm 1 0.6202 13.164 -1134.7
- eptratio 1 0.6680 13.212 -1133.4
- lrad 1 1.0026 13.547 -1124.6
- lcrim 1 1.3176 13.861 -1116.5
- ldis 1 1.4130 13.957 -1114.1
- srlstat 1 5.1337 17.678 -1031.0</p>
</blockquote>
<pre class="r"><code># Multicollinearity suspect: Promising variables (Severe)
summary_relationship_tbl %&gt;% 
  filter(str_detect(label, pattern = &quot;chas&quot;))</code></pre>
<pre><code>## [1] var_names  Estimate   t_stats    p_value    corr       label      cross_corr
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
</div>
